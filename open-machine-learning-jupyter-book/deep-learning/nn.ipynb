{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc99d119-6597-4d49-b013-f31694aed38e",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Install the necessary dependencies\n",
    "\n",
    "import os\n",
    "import sys \n",
    "!{sys.executable} -m pip install --quiet pandas scikit-learn numpy matplotlib jupyterlab_myst ipython imageio scikit-image requests ucimlrepo seaborn keras\n",
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e69c41-73fc-43dd-a615-9db97592b588",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "---\n",
    "license:\n",
    "    code: MIT\n",
    "    content: CC-BY-4.0\n",
    "github: https://github.com/ocademy-ai/machine-learning\n",
    "venue: By Ocademy\n",
    "open_access: true\n",
    "bibliography:\n",
    "  - https://raw.githubusercontent.com/ocademy-ai/machine-learning/main/open-machine-learning-jupyter-book/references.bib\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec28bbd0-5ff6-48ab-bd15-f92783e6a183",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c9021c-c560-485d-91f2-1642c6402ac5",
   "metadata": {},
   "source": [
    "Neural Networks are the functional unit of [Deep Learning](https://press.ocademy.cc/deep-learning/dl-overview.html) and are known to mimic the behavior of the human brain to solve complex data-driven problems.\n",
    "The input data is processed through different layers of artificial neurons stacked together to produce the desired output.\n",
    "From speech recognition and person recognition to healthcare and marketing, Neural Networks have been used in a varied set of domains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2d8e9d-ffb2-4562-a180-92e5e9a87d79",
   "metadata": {},
   "source": [
    "## Key Components of the Neural Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460b8583-75ed-47ff-bea0-18913ac02aba",
   "metadata": {},
   "source": [
    "The Neural Network architecture is made of individual units called neurons that mimic the biological behavior of the brain. \n",
    "Here are the various components of a neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11568845-e197-4e99-be19-27509431a4c1",
   "metadata": {},
   "source": [
    "<img src=\"https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/nn/Neuron%20in%20Artificial%20Neural%20Network.png\" width=\"90%\" class=\"bg-white mb-1\"><br> Image: Neuron in Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6cd958-b6af-4f18-ad97-83307a697c7c",
   "metadata": {},
   "source": [
    "### Input\n",
    "It is the set of features that are fed into the model for the learning process. For example, the input in object detection can be an array of pixel values pertaining to an image.\n",
    "\n",
    "### Weight\n",
    "Its main function is to give importance to those features that contribute more towards the learning. It does so by introducing scalar multiplication between the input value and the weight matrix. For example, a negative word would impact the decision of the sentiment analysis model more than a pair of neutral words.\n",
    "\n",
    "### Transfer function\n",
    "The job of the transfer function is to combine multiple inputs into one output value so that the activation function can be applied. It is done by a simple summation of all the inputs to the transfer function. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f32b90-5cc1-41fb-93a5-7776d9b3d9c2",
   "metadata": {},
   "source": [
    "### Activation Function\n",
    "It introduces non-linearity in the working of perceptrons to consider varying linearity with the inputs. Without this, the output would just be a linear combination of input values and would not be able to introduce non-linearity in the network.\n",
    "In the realm of deep learning, several common activation functions are widely used due to their impact on network training and performance. Here are some prevalent activation functions:\n",
    "#### 1. ReLU (Rectified Linear Activation):\n",
    "ReLU is one of the most commonly used activation functions. It sets negative input values to zero and keeps positive values unchanged:\n",
    "\n",
    "$$\n",
    "f(x) = \\max(0, x) \n",
    "$$\n",
    "\n",
    "ReLU effectively mitigates the vanishing gradient problem and computes faster. However, it can cause neurons to \"die\" by setting negative outputs to zero.\n",
    "#### 2. Sigmoid Function:\n",
    "The sigmoid function maps inputs to the range (0, 1):\n",
    "\n",
    "$$\n",
    "f(x) = \\frac{1}{1 + e^{-x}}\n",
    "$$\n",
    "\n",
    "It's often used in binary classification problems at the output layer but suffers from the vanishing gradient problem in deep neural networks.\n",
    "#### 3. Tanh Function:\n",
    "Tanh function maps inputs to the range (-1, 1):\n",
    "\n",
    "$$\n",
    "f(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}\n",
    "$$\n",
    "\n",
    "Similar to the sigmoid function but outputs in the range (-1, 1), aiding zero-centered data. However, it also faces the issue of vanishing gradients.\n",
    "#### 4. Leaky ReLU:\n",
    "Leaky ReLU is an improvement over ReLU, allowing a small slope for negative input values:\n",
    "\n",
    "$$\n",
    "f(x) = \\begin{cases} x & \\text{if } x > 0 \\\\ \\alpha x & \\text{otherwise} \\end{cases}\n",
    "$$\n",
    "\n",
    "Where $\\alpha$ is a small positive number. This function addresses the \"neuron death\" problem in ReLU.\n",
    "#### 5. ELU (Exponential Linear Unit):\n",
    "ELU is similar to Leaky ReLU but allows a slightly negative slope for negative values and tends to zero-center:\n",
    "\n",
    "$$\n",
    "f(x) = \\begin{cases} x & \\text{if } x > 0 \\\\ \\alpha (e^x - 1) & \\text{otherwise} \\end{cases}\n",
    "$$\n",
    "    \n",
    "ELU helps reduce the vanishing gradient problem and improves training stability in some scenarios.\n",
    "\n",
    "Each activation function has its advantages and drawbacks. Their performance can vary in different network architectures and tasks. Research in deep learning continually explores new activation functions to enhance training effectiveness and network performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5137abb6-81fa-4ab6-aa57-28d215074735",
   "metadata": {},
   "source": [
    "### Bias\n",
    "The role of bias is to shift the value produced by the activation function. Its role is similar to the role of a constant in a linear function.\n",
    "\n",
    "When multiple neurons are stacked together in a row, they constitute a layer, and multiple layers piled next to each other are called a multi-layer neural network.\n",
    "\n",
    "We've described the main components of this type of structure below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19aeaa65-4f77-47cf-8c98-9ce0ba304908",
   "metadata": {},
   "source": [
    "<img src=\"https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/nn/Multi-layer%20neural%20network.png\" width=\"90%\" class=\"bg-white mb-1\"><br> Image: Multi-layer neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb44613-7e13-41a9-a621-bec3327a9ed2",
   "metadata": {},
   "source": [
    "### Input Layer\n",
    "\n",
    "The data that we feed to the model is loaded into the input layer from external sources like a CSV file or a web service. It is the only visible layer in the complete Neural Network architecture that passes the complete information from the outside world without any computation.\n",
    "\n",
    "### Hidden Layers\n",
    "\n",
    "The hidden layers are what makes deep learning what it is today. They are intermediate layers that do all the computations and extract the features from the data.\n",
    "\n",
    "There can be multiple interconnected hidden layers that account for searching different hidden features in the data. For example, in image processing, the first hidden layers are responsible for higher-level features like edges, shapes, or boundaries. On the other hand, the later hidden layers perform more complicated tasks like identifying complete objects (a car, a building, a person).\n",
    "\n",
    "### Output Layer\n",
    "\n",
    "The output layer takes input from preceding hidden layers and comes to a final prediction based on the model’s learnings. It is the most important layer where we get the final result.\n",
    "\n",
    "In the case of classification/regression models, the output layer generally has a single node. However, it is completely problem-specific and dependent on the way the model was built."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b6b84a-b5cd-4cd9-89b6-3945ba0505ed",
   "metadata": {},
   "source": [
    "## Standard Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e9a68e-2b30-44b6-b651-d80e871f5ddc",
   "metadata": {},
   "source": [
    "The following are several standard types of neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8abe53-1148-41cc-9651-2bcb0a3e916e",
   "metadata": {},
   "source": [
    "### The Perceptron\n",
    "Perceptron is the simplest Neural Network architecture.\n",
    "\n",
    "It is a type of  Neural Network that takes a number of inputs, applies certain mathematical operations on these inputs, and produces an output. It takes a vector of real values inputs, performs a linear combination of each attribute with the corresponding weight assigned to each of them.\n",
    "\n",
    "The weighted input is summed into a single value and passed through an activation function. \n",
    "\n",
    "These perceptron units are combined to form a bigger Artificial Neural Network architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02af3b8a-5251-4fff-8d16-87fbf1d7a87b",
   "metadata": {},
   "source": [
    "### Feed-Forward Networks\n",
    "Perceptron represents how a single neuron works.\n",
    "\n",
    "But—\n",
    "\n",
    "What about a series of perceptrons stacked in a row and piled in different layers? How does the model learn then?\n",
    "\n",
    "It is a multi-layer Neural Network, and, as the name suggests, the information is passed in the forward direction—from left to right.\n",
    "\n",
    "In the forward pass, the information comes inside the model through the input layer, passes through the series of hidden layers, and finally goes to the output layer. This Neural Networks architecture is forward in nature—the information does not loop with two hidden layers.\n",
    "\n",
    "The later layers give no feedback to the previous layers. The basic learning process of Feed-Forward Networks remain the same as the perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f7dc96-ab00-4b00-827a-5790918ed462",
   "metadata": {},
   "source": [
    "### Residual Networks (ResNet)\n",
    "Now that you know more about the Feed-Forward Networks, one question might have popped up in your head—how to decide on the number of layers in our neural network architecture?\n",
    "\n",
    "A naive answer would be: The greater the number of hidden layers, the better is the learning process.\n",
    "\n",
    "More layers enrich the levels of features.\n",
    "\n",
    "But—\n",
    "\n",
    "Is that so?\n",
    "\n",
    "Very deep Neural Networks are extremely difficult to train due to vanishing and exploding gradient problems.\n",
    "\n",
    "ResNets provide an alternate pathway for data to flow to make the training process much faster and easier.\n",
    "\n",
    "This is different from the feed-forward approach of earlier Neural Networks architectures. \n",
    "\n",
    "The core idea behind ResNet is that a deeper network can be made from a shallow network by copying weight from the shallow counterparts using identity mapping.\n",
    "\n",
    "The data from previous layers is fast-forwarded and copied much forward in the Neural Networks. This is what we call skip connections first introduced in Residual Networks to resolve vanishing gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59bd0fe-75ec-473a-aacc-cac0e6eccb35",
   "metadata": {},
   "source": [
    "## Code\n",
    "Now, let's train a neural network model for Heart Disease Classification as an example to help you better understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "7aaffb2a-8b9c-49e4-944d-884969408638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 1s 1ms/step - loss: 0.6931 - accuracy: 0.5331\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5331\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5331\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5331\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6767 - accuracy: 0.5372\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6246 - accuracy: 0.8347\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5233 - accuracy: 0.8719\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4264 - accuracy: 0.8719\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3577 - accuracy: 0.8760\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3254 - accuracy: 0.8802\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3170 - accuracy: 0.8843\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3123 - accuracy: 0.8843\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3085 - accuracy: 0.8843\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3047 - accuracy: 0.8926\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2998 - accuracy: 0.8926\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2968 - accuracy: 0.8967\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2942 - accuracy: 0.9008\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2920 - accuracy: 0.9008\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2902 - accuracy: 0.9008\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2871 - accuracy: 0.9008\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2850 - accuracy: 0.9008\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2832 - accuracy: 0.9050\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2822 - accuracy: 0.9008\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2796 - accuracy: 0.9008\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2787 - accuracy: 0.9050\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2743 - accuracy: 0.9091\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2740 - accuracy: 0.9091\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.2714 - accuracy: 0.9091\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2710 - accuracy: 0.9132\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2681 - accuracy: 0.9091\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2674 - accuracy: 0.9091\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2656 - accuracy: 0.9132\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2642 - accuracy: 0.9132\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2627 - accuracy: 0.9132\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2609 - accuracy: 0.9132\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.2603 - accuracy: 0.9132\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2580 - accuracy: 0.9132\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2578 - accuracy: 0.9132\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2570 - accuracy: 0.9132\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2546 - accuracy: 0.9132\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2528 - accuracy: 0.9132\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2515 - accuracy: 0.9132\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.2488 - accuracy: 0.9132\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2470 - accuracy: 0.9132\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2451 - accuracy: 0.9132\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2434 - accuracy: 0.9174\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2401 - accuracy: 0.9256\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2393 - accuracy: 0.9256\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2367 - accuracy: 0.9256\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2360 - accuracy: 0.9256\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2340 - accuracy: 0.9256\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2313 - accuracy: 0.9256\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2300 - accuracy: 0.9256\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2277 - accuracy: 0.9256\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2264 - accuracy: 0.9256\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2283 - accuracy: 0.9256\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2292 - accuracy: 0.9256\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.2223 - accuracy: 0.9298\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.2191 - accuracy: 0.9298\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.2168 - accuracy: 0.9298\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.2152 - accuracy: 0.9339\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2130 - accuracy: 0.9339\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2123 - accuracy: 0.9339\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2102 - accuracy: 0.9339\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2091 - accuracy: 0.9339\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2074 - accuracy: 0.9339\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2073 - accuracy: 0.9298\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2018 - accuracy: 0.9339\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2012 - accuracy: 0.9339\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1999 - accuracy: 0.9339\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1983 - accuracy: 0.9380\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.1961 - accuracy: 0.9380\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1950 - accuracy: 0.9380\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1925 - accuracy: 0.9380\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1906 - accuracy: 0.9380\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1894 - accuracy: 0.9380\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1896 - accuracy: 0.9380\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.1847 - accuracy: 0.9380\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1820 - accuracy: 0.9421\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1798 - accuracy: 0.9421\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1774 - accuracy: 0.9421\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1766 - accuracy: 0.9421\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1740 - accuracy: 0.9421\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1742 - accuracy: 0.9421\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1701 - accuracy: 0.9421\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1685 - accuracy: 0.9421\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1660 - accuracy: 0.9421\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1653 - accuracy: 0.9463\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1642 - accuracy: 0.9421\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1616 - accuracy: 0.9463\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1592 - accuracy: 0.9463\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1577 - accuracy: 0.9463\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1551 - accuracy: 0.9463\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1498 - accuracy: 0.9504\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1481 - accuracy: 0.9545\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1444 - accuracy: 0.9545\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.1418 - accuracy: 0.9545\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1400 - accuracy: 0.9545\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1388 - accuracy: 0.9545\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1371 - accuracy: 0.9545\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "accuracy of the model:  0.8032786885245902\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "%matplotlib inline\n",
    "heart_disease = fetch_ucirepo(id=45)\n",
    "pd.options.mode.chained_assignment = None\n",
    "X = heart_disease.data.features \n",
    "y = heart_disease.data.targets\n",
    "y[y != 0] = 1\n",
    "chest_pain = pd.get_dummies(X['cp'], prefix='cp', drop_first=True)\n",
    "X = pd.concat([X, chest_pain], axis=1)\n",
    "X.drop(['cp'], axis=1, inplace=True)\n",
    "\n",
    "sp = pd.get_dummies(X['slope'], prefix='slope')\n",
    "th = pd.get_dummies(X['thal'], prefix='thal')\n",
    "rest_ecg = pd.get_dummies(X['restecg'], prefix='restecg')\n",
    "\n",
    "frames = [X, sp, th, rest_ecg]\n",
    "X = pd.concat(frames, axis=1)\n",
    "X.drop(['slope', 'thal', 'restecg'], axis=1, inplace=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train).fillna(method='ffill')\n",
    "X_test = pd.DataFrame(X_test).fillna(method='ffill')\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=11, kernel_initializer='uniform', activation='relu', input_dim=21))\n",
    "classifier.add(Dense(units=10, kernel_initializer='uniform', activation='relu'))\n",
    "classifier.add(Dense(units=10, kernel_initializer='uniform', activation='relu'))\n",
    "classifier.add(Dense(units=5, kernel_initializer='uniform', activation='relu'))\n",
    "classifier.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "classifier.fit(X_train, y_train, batch_size=10, epochs=100)\n",
    "y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred.round())\n",
    "sns.heatmap(cm,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False)\n",
    "ac=accuracy_score(y_test, y_pred.round())\n",
    "print('accuracy of the model: ',ac)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb10720d-9756-4ce8-a284-18a882e11f64",
   "metadata": {},
   "source": [
    "## Your turn! 🚀\n",
    "\n",
    "TBD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc673adb-1d3a-4ea5-b9b6-c84b45953be0",
   "metadata": {},
   "source": [
    "## Self study\n",
    "\n",
    "TBD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5b2350-2265-4919-9503-8f191fb33a52",
   "metadata": {},
   "source": [
    "## Acknowledgments\n",
    "\n",
    "Thanks to [Pragati Baheti](https://www.v7labs.com/authors/pragati-baheti) and [Rajesh kumar jha](https://www.kaggle.com/rajeshjnv) for creating the open-source course [The Essential Guide to Neural Network Architectures](https://www.v7labs.com/blog/neural-network-architectures-guide#standard-neural-networks) and [Heart Disease Classification - Neural Network](https://www.kaggle.com/code/rajeshjnv/heart-disease-classification-neural-network#Loading-appropriate-libraries). It inspires the majority of the content in this chapter.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open-machine-learning-jupyter-book",
   "language": "python",
   "name": "open-machine-learning-jupyter-book"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
